{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAgP4pH1vWVz"
      },
      "source": [
        "# Denis Shirvaey youtube channel b/w to color \r\n",
        "\r\n",
        "# Data Aug\r\n",
        "# Medical Applications\r\n",
        "# Semi -seupervised GANs\r\n",
        "\r\n",
        "# GANS ?\r\n",
        "A calss of ML techniques that consists of two networks playing an adversarial game against each other.\r\n",
        "-Generator\r\n",
        "-Detector\r\n",
        "# Loss Function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgisfuMQ9HkS"
      },
      "source": [
        "import torch \r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torchvision\r\n",
        "import torchvision.datasets as datasets\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArqkNVRP9c-5"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self, img_dim):\r\n",
        "        super().__init__()\r\n",
        "        self.disc = nn.Sequential(\r\n",
        "            nn.Linear(img_dim, 128),\r\n",
        "            nn.LeakyReLU(0.1),\r\n",
        "            nn.Linear(128, 1),\r\n",
        "            nn.Sigmoid(),\r\n",
        "        )\r\n",
        "    def forward(self, x):\r\n",
        "        return self.disc(x)\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    def __init__(self, z_dim, img_dim):\r\n",
        "        super().__init__()\r\n",
        "        self.gen = nn.Sequential(\r\n",
        "            nn.Linear(z_dim, 256),\r\n",
        "            nn.LeakyReLU(0.1),\r\n",
        "            nn.Linear(256, img_dim),\r\n",
        "            nn.Tanh(),\r\n",
        "        )\r\n",
        "    def forward(self, x):\r\n",
        "        return self.gen(x)\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CICdVxUT_ArI"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giZh8q1n_G3P"
      },
      "source": [
        "lr = 3e-4# best learning rate said by Andrej Karpathy for Adam\r\n",
        "z_dim = 64# gans are sensitive to hyperparametrs in this case\r\n",
        "img_dim = 28*28*1\r\n",
        "batch_size =32\r\n",
        "num_epochs = 50"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rtRxuU_Z8e"
      },
      "source": [
        "disc = Discriminator(img_dim).to(device)\r\n",
        "gen = Generator(z_dim, img_dim).to(device)\r\n",
        "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\r\n",
        "transforms = transforms.Compose(\r\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\r\n",
        ")\r\n",
        "dataset = datasets.MNIST(root = 'dataset/', transform=transforms, download = True)\r\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle = True)\r\n",
        "opt_disc = optim.Adam(disc.parameters(), lr = lr)\r\n",
        "opt_gen = optim.Adam(gen.parameters(), lr = lr)\r\n",
        "criterion = nn.BCELoss()\r\n",
        "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\r\n",
        "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\r\n",
        "step = 0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acje6VriG4nj",
        "outputId": "7eacd21d-a608-4797-d92d-3f98e5fd6720"
      },
      "source": [
        "!tensorboard --logdir='runs/GAN_MNIST/fake' --host localhost --port 8088"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-30 14:56:16.484922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "TensorBoard 2.4.0 at http://localhost:8088/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiXEnPL8IXmX",
        "outputId": "10a7138e-9f8e-4126-b6dc-3d347a126b7e"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "!tensorboard --logdir logs/tensorboard"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-30 14:51:13.164208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.4.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrsC_v7pHW-a",
        "outputId": "b9e1991a-d216-4352-d9b0-1b607563e939"
      },
      "source": [
        "!tensorboard --bind_all --port 8088 --logdir ./logs"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-30 14:47:00.043193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "TensorBoard 2.4.0 at http://b3b38870a7e2:8088/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ-A2GelBUd2",
        "outputId": "0c1a6e8e-7bb5-47fe-d7ef-61773959159e"
      },
      "source": [
        "for epoch in range(num_epochs):\r\n",
        "    for batch_idx, (real, _) in enumerate(loader):\r\n",
        "        real = real.view(-1, 784).to(device)\r\n",
        "        batch_size = real.shape[0]\r\n",
        "\r\n",
        "        noise = torch.randn(batch_size, z_dim).to(device)\r\n",
        "        fake = gen(noise)\r\n",
        "        disc_real = disc(real).view(-1)\r\n",
        "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\r\n",
        "        disc_fake = disc(fake).view(-1) # fake.detach()\r\n",
        "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\r\n",
        "        lossD = (lossD_real + lossD_fake)/2\r\n",
        "        disc.zero_grad()\r\n",
        "        lossD.backward(retain_graph =True)\r\n",
        "        opt_disc.step()\r\n",
        "\r\n",
        "        output = disc(fake).view(-1)\r\n",
        "        lossG = criterion(output, torch.ones_like(output))\r\n",
        "        gen.zero_grad()\r\n",
        "        lossG.backward()\r\n",
        "        opt_gen.step()\r\n",
        "        if batch_idx == 0:\r\n",
        "            print(\r\n",
        "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\r\n",
        "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\r\n",
        "            )\r\n",
        "\r\n",
        "            with torch.no_grad():\r\n",
        "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\r\n",
        "                data = real.reshape(-1, 1, 28, 28)\r\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\r\n",
        "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\r\n",
        "\r\n",
        "                writer_fake.add_image(\r\n",
        "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\r\n",
        "                )\r\n",
        "                writer_real.add_image(\r\n",
        "                    \"Mnist Real Images\", img_grid_real, global_step=step\r\n",
        "                )\r\n",
        "                step += 1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/50] Batch 0/1875                       Loss D: 0.0492, loss G: 4.0868\n",
            "Epoch [1/50] Batch 0/1875                       Loss D: 0.0112, loss G: 5.2670\n",
            "Epoch [2/50] Batch 0/1875                       Loss D: 0.0105, loss G: 4.7350\n",
            "Epoch [3/50] Batch 0/1875                       Loss D: 0.0118, loss G: 5.0453\n",
            "Epoch [4/50] Batch 0/1875                       Loss D: 0.0082, loss G: 4.9246\n",
            "Epoch [5/50] Batch 0/1875                       Loss D: 0.0428, loss G: 4.2810\n",
            "Epoch [6/50] Batch 0/1875                       Loss D: 0.0061, loss G: 6.4411\n",
            "Epoch [7/50] Batch 0/1875                       Loss D: 0.0116, loss G: 5.6784\n",
            "Epoch [8/50] Batch 0/1875                       Loss D: 0.0044, loss G: 6.4064\n",
            "Epoch [9/50] Batch 0/1875                       Loss D: 0.0203, loss G: 5.6259\n",
            "Epoch [10/50] Batch 0/1875                       Loss D: 0.0093, loss G: 5.8809\n",
            "Epoch [11/50] Batch 0/1875                       Loss D: 0.0184, loss G: 6.7507\n",
            "Epoch [12/50] Batch 0/1875                       Loss D: 0.0029, loss G: 6.9328\n",
            "Epoch [13/50] Batch 0/1875                       Loss D: 0.0165, loss G: 6.2837\n",
            "Epoch [14/50] Batch 0/1875                       Loss D: 0.0058, loss G: 7.4972\n",
            "Epoch [15/50] Batch 0/1875                       Loss D: 0.0138, loss G: 5.0495\n",
            "Epoch [16/50] Batch 0/1875                       Loss D: 0.0085, loss G: 5.9578\n",
            "Epoch [17/50] Batch 0/1875                       Loss D: 0.0063, loss G: 6.6752\n",
            "Epoch [18/50] Batch 0/1875                       Loss D: 0.0692, loss G: 7.3821\n",
            "Epoch [19/50] Batch 0/1875                       Loss D: 0.0530, loss G: 7.9139\n",
            "Epoch [20/50] Batch 0/1875                       Loss D: 0.0048, loss G: 7.0157\n",
            "Epoch [21/50] Batch 0/1875                       Loss D: 0.1199, loss G: 8.0906\n",
            "Epoch [22/50] Batch 0/1875                       Loss D: 0.0036, loss G: 7.0295\n",
            "Epoch [23/50] Batch 0/1875                       Loss D: 0.0005, loss G: 8.1265\n",
            "Epoch [24/50] Batch 0/1875                       Loss D: 0.0034, loss G: 7.0886\n",
            "Epoch [25/50] Batch 0/1875                       Loss D: 0.0020, loss G: 8.3889\n",
            "Epoch [26/50] Batch 0/1875                       Loss D: 0.0017, loss G: 8.1796\n",
            "Epoch [27/50] Batch 0/1875                       Loss D: 0.0003, loss G: 8.4913\n",
            "Epoch [28/50] Batch 0/1875                       Loss D: 0.0032, loss G: 7.3776\n",
            "Epoch [29/50] Batch 0/1875                       Loss D: 0.0005, loss G: 8.6805\n",
            "Epoch [30/50] Batch 0/1875                       Loss D: 0.0156, loss G: 7.7744\n",
            "Epoch [31/50] Batch 0/1875                       Loss D: 0.0015, loss G: 7.1767\n",
            "Epoch [32/50] Batch 0/1875                       Loss D: 0.0059, loss G: 7.9340\n",
            "Epoch [33/50] Batch 0/1875                       Loss D: 0.0039, loss G: 7.5512\n",
            "Epoch [34/50] Batch 0/1875                       Loss D: 0.0084, loss G: 9.3361\n",
            "Epoch [35/50] Batch 0/1875                       Loss D: 0.0083, loss G: 10.3369\n",
            "Epoch [36/50] Batch 0/1875                       Loss D: 0.0068, loss G: 6.6855\n",
            "Epoch [37/50] Batch 0/1875                       Loss D: 0.0090, loss G: 7.6347\n",
            "Epoch [38/50] Batch 0/1875                       Loss D: 0.0024, loss G: 8.4865\n",
            "Epoch [39/50] Batch 0/1875                       Loss D: 0.0037, loss G: 8.7554\n",
            "Epoch [40/50] Batch 0/1875                       Loss D: 0.0026, loss G: 7.9857\n",
            "Epoch [41/50] Batch 0/1875                       Loss D: 0.0064, loss G: 7.7265\n",
            "Epoch [42/50] Batch 0/1875                       Loss D: 0.0049, loss G: 9.4104\n",
            "Epoch [43/50] Batch 0/1875                       Loss D: 0.0007, loss G: 9.1056\n",
            "Epoch [44/50] Batch 0/1875                       Loss D: 0.0022, loss G: 7.9803\n",
            "Epoch [45/50] Batch 0/1875                       Loss D: 0.0023, loss G: 8.3011\n",
            "Epoch [46/50] Batch 0/1875                       Loss D: 0.0101, loss G: 7.2974\n",
            "Epoch [47/50] Batch 0/1875                       Loss D: 0.0014, loss G: 8.6555\n",
            "Epoch [48/50] Batch 0/1875                       Loss D: 0.0000, loss G: 12.4895\n",
            "Epoch [49/50] Batch 0/1875                       Loss D: 0.0008, loss G: 9.2258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEnBgXwTGGMX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}